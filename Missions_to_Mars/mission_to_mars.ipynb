{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to chromedriver\n",
    "executable_path = {\"executable_path\": \"C:/bin/chromedriver\"}\n",
    "browser=Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA Moves Forward With Campaign to Return Mars Samples to Earth\n",
      "During this next phase, the program will mature critical technologies and make critical design decisions as well as assess industry partnerships.\n"
     ]
    }
   ],
   "source": [
    "# Build query URL for NASA news (using Splinter to scrape)\n",
    "url = \"https://mars.nasa.gov/news/\"\n",
    "browser.visit(url)\n",
    "\n",
    "# Scrape page into Soup\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Collect the latest News Title and Paragraph Text\n",
    "# Assign the text to variables that you can reference later\n",
    "news_title = soup.find('div', class_='bottom_gradient').text\n",
    "news_p = soup.find('div', class_='article_teaser_body').text\n",
    "\n",
    "print(news_title)\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA16227-1920x1200.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build query URL for JPL featured [Mars] image - use Splinter to scrape\n",
    "url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(url)\n",
    "\n",
    "# Scrape page into Soup\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Find the image url for the current Featured Mars Image\n",
    "#featured_image_url = soup.find('a', class_='carousel_item', style) ## produces error\n",
    "#featured_image_url = soup.find('a', class_='carousel_item')['style'] ## produces error\n",
    "#featured_image_url = soup.find('article', class_='carousel_item')['style'] ## includes unneeded control text\n",
    "\n",
    "# Removed uneeded control text\n",
    "#featured_image_url = soup.find('article', class_='carousel_item')['style'].replace('background-image: url(','')\n",
    "#featured_image_url = soup.find('article', class_='carousel_item')['style'].replace('background-image: url(','').replace(');', '')  ## includes quotes\n",
    "\n",
    "# Find the image url for the current Featured Mars Image and remove unneeded control text\n",
    "featured_image_url = soup.find('article', class_='carousel_item')['style'].\\\n",
    "                        replace('background-image: url(','').\\\n",
    "                        replace(');', '')[1:-1]\n",
    "\n",
    "\n",
    "\n",
    "# image url from html only makes sense when referenced in source site - add source site to front of url\n",
    "featured_image_url = \"https://www.jpl.nasa.gov\" + featured_image_url\n",
    "\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tables: 3\n",
      "\n",
      "<table border=\"1\" class=\"dataframe\">\n",
      "  <thead>\n",
      "    <tr style=\"text-align: right;\">\n",
      "      <th></th>\n",
      "      <th>Mars - Earth Comparison</th>\n",
      "      <th>Mars</th>\n",
      "      <th>Earth</th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <th>0</th>\n",
      "      <td>Diameter:</td>\n",
      "      <td>6,779 km</td>\n",
      "      <td>12,742 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>1</th>\n",
      "      <td>Mass:</td>\n",
      "      <td>6.39 × 10^23 kg</td>\n",
      "      <td>5.97 × 10^24 kg</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>2</th>\n",
      "      <td>Moons:</td>\n",
      "      <td>2</td>\n",
      "      <td>1</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>3</th>\n",
      "      <td>Distance from Sun:</td>\n",
      "      <td>227,943,824 km</td>\n",
      "      <td>149,598,262 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>4</th>\n",
      "      <td>Length of Year:</td>\n",
      "      <td>687 Earth days</td>\n",
      "      <td>365.24 days</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>5</th>\n",
      "      <td>Temperature:</td>\n",
      "      <td>-87 to -5 °C</td>\n",
      "      <td>-88 to 58°C</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "# Visit the Mars Facts webpage and use Pandas to scrape the table\n",
    "results = pd.read_html(\"https://space-facts.com/mars/\")\n",
    "print(f'Total tables: {len(results)}')\n",
    "print()\n",
    "facts_df1 = results[0]\n",
    "facts_df2 = results[1]\n",
    "facts_df3 = results[2]\n",
    "\n",
    "# Use Pandas to convert the data to a HTML table string\n",
    "facts_html1 = facts_df1.to_html()\n",
    "facts_html2 = facts_df2.to_html()\n",
    "facts_html3 = facts_df3.to_html()\n",
    "\n",
    "#print(facts_html1)\n",
    "print(facts_html2)\n",
    "#print(facts_html3)\n",
    "\n",
    "#facts_df = pd.DataFrame(results)\n",
    "#facts_html = facts_df.to_html()\n",
    "#print(facts_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced'},\n",
       " {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/schiaparelli_enhanced'},\n",
       " {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/syrtis_major_enhanced'},\n",
       " {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visit the USGS Astrogeology site to obtain high resolution images for each of Mar's hemispheres\n",
    "# Build query URL for page in USGS Astrogeology site that has pics of Mars' hemispheres\n",
    "url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(url)\n",
    "\n",
    "# Scrape page into Soup\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "images = soup.find_all('div', class_='item')\n",
    "\n",
    "# Save both the image url string and the Hemisphere title containing the hemisphere name. \n",
    "# Use a Python dictionary to store the data using the keys img_url and title.\n",
    "\n",
    "hemisphere_image_urls = []\n",
    "for i in images:\n",
    "    url = \"https://astrogeology.usgs.gov\" + i.find('a')['href']\n",
    "#    print(url)\n",
    "    title = i.find('h3').text.strip()\n",
    "#    print(title)\n",
    "    hemisphere_image_urls.append({'title':title,'img_url':url})\n",
    "\n",
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
